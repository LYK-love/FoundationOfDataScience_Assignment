# Python爬虫——基本库的使用

| 库名称 | 简介                                                   |
| ------ | ------------------------------------------------------ |
| urllib | 时python内置的一个HTTP请求库，不需要额外安装即可使用。 |













## urllib库



#### 四个模块

| 模块名称      | 模块简介                                                     |
| ------------- | ------------------------------------------------------------ |
| `request`     | 它是最基本的 HTTP 请求模块，可以用来模拟发送请求。就像在浏览器里输入网址然后回车一样，只需要给库方法传入 URL 以及额外的参数，就可以模拟实现这个过程了。 |
| `error`       | 异常处理模块，如果出现请求错误，我们可以捕获这些异常，然后进行重试或其他操作以保证程序不会意外终止。 |
| `parse`       | 一个工具模块，提供了许多 URL 处理方法，比如拆分、解析、合并等。 |
| `robotparser` | 主要是用来识别网站的 robots.txt 文件，然后判断哪些网站可以爬，哪些网站不可以爬，它其实用得比较少。 |

- `request`模块

  - `urlopen()`方法：

    - 方法api：

      ```python
      urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)
      ```

    - 功能：

      完成最基本的简单网页的**GET**请求抓取。

    - 参数介绍：

      | 参数   | 类型                                                         | 含义                                                         |
      | ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | `url`  | 字符串                                                       | 网址（URL）                                                  |
      | `data` | 字节流（`bytes`）**注意**：可以使用`bytes()`函数将一个`str`类型转化成`bytes`类型。 | 如果选择传入该参数，则`urlopen()`方法发送的请求不再时一个**GET**类型的请求，而是一个**POST**类型的请求，该请求的提交方式为表单提交方式，表单数据中的参数名和参数值由该`data`参数决定。我们可以借助`urllib.parse.urlencode()`方法来以字典形式指定参数名和参数方法。 |

  |`urlopen()`

  